{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "95156301083044c29d74cd4994d370b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_70134ae25a424b3a9920d4dc061cc904",
              "IPY_MODEL_aa6f196c4dc74392bcbb13225c14e027",
              "IPY_MODEL_63a18c9ea0684e60a21a76ced45f58aa"
            ],
            "layout": "IPY_MODEL_688a6e5f13f3402d92a3e0e52b0b3f91"
          }
        },
        "70134ae25a424b3a9920d4dc061cc904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afd353f84ee34a6995d96b6cb59d27dc",
            "placeholder": "​",
            "style": "IPY_MODEL_7423da0839b74087991807ca271f2ef5",
            "value": "Fetching 1 files: 100%"
          }
        },
        "aa6f196c4dc74392bcbb13225c14e027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ee89a2ac3d043c494f2754b5417cbf7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed8efe638aba465195513218f25ba707",
            "value": 1
          }
        },
        "63a18c9ea0684e60a21a76ced45f58aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15c4b03a8f36498393c341f060883a4b",
            "placeholder": "​",
            "style": "IPY_MODEL_1fc8cc9db1db4561a6c2863abf76fa7e",
            "value": " 1/1 [00:00&lt;00:00, 62.21it/s]"
          }
        },
        "688a6e5f13f3402d92a3e0e52b0b3f91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afd353f84ee34a6995d96b6cb59d27dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7423da0839b74087991807ca271f2ef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ee89a2ac3d043c494f2754b5417cbf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed8efe638aba465195513218f25ba707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15c4b03a8f36498393c341f060883a4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fc8cc9db1db4561a6c2863abf76fa7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDb-E0D9KWRn"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-cloud\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w28kpn0MKs_8",
        "outputId": "7e532a43-f0e3-4a5f-dc7a-649f65464f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud in /usr/local/lib/python3.12/dist-packages (0.34.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = \"astral-net-472017-i3\"\n"
      ],
      "metadata": {
        "id": "VlTvKjhBKwqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud config set project astral-net-472017-i3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dj6WOaPvMjW5",
        "outputId": "45cb82eb-d8ea-4eea-da39-47543ddd9c69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud config get-value project\n"
      ],
      "metadata": {
        "id": "h271gKMaM42F",
        "outputId": "418d55d9-8538-4e3e-f10d-686bf0238cad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "astral-net-472017-i3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud services enable compute.googleapis.com\n",
        "!gcloud services enable storage.googleapis.com\n"
      ],
      "metadata": {
        "id": "a5UjuTicM6nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoImageProcessor, AutoModelForImageClassification, pipeline\n",
        "\n",
        "# Load processor & model\n",
        "processor = AutoImageProcessor.from_pretrained(\"prithivMLmods/Deep-Fake-Detector-v2-Model\")\n",
        "model = AutoModelForImageClassification.from_pretrained(\"prithivMLmods/Deep-Fake-Detector-v2-Model\")\n",
        "\n",
        "# Create pipeline (use image_processor instead of tokenizer)\n",
        "pipe = pipeline(\"image-classification\", model=model, image_processor=processor)\n",
        "\n",
        "# Test\n",
        "result = pipe(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/parrots.png\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225,
          "referenced_widgets": [
            "95156301083044c29d74cd4994d370b3",
            "70134ae25a424b3a9920d4dc061cc904",
            "aa6f196c4dc74392bcbb13225c14e027",
            "63a18c9ea0684e60a21a76ced45f58aa",
            "688a6e5f13f3402d92a3e0e52b0b3f91",
            "afd353f84ee34a6995d96b6cb59d27dc",
            "7423da0839b74087991807ca271f2ef5",
            "3ee89a2ac3d043c494f2754b5417cbf7",
            "ed8efe638aba465195513218f25ba707",
            "15c4b03a8f36498393c341f060883a4b",
            "1fc8cc9db1db4561a6c2863abf76fa7e"
          ]
        },
        "id": "pYwWdj4AYqsB",
        "outputId": "e34fd181-58d2-4d52-da02-0f2778a72749"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95156301083044c29d74cd4994d370b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'Deepfake', 'score': 0.7101955413818359}, {'label': 'Realism', 'score': 0.28980448842048645}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"deepfake_model\")\n",
        "processor.save_pretrained(\"deepfake_model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2z9JGPLZQ-F",
        "outputId": "04eebe4b-8d3f-43a6-8eb2-504e38322387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['deepfake_model/preprocessor_config.json']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil cp -r deepfake_model gs://hackathon1512/deepfake_model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4RGPNkTZVu2",
        "outputId": "cf696826-0037-42ff-86af-c4655fb614d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying file://deepfake_model/preprocessor_config.json [Content-Type=application/json]...\n",
            "Copying file://deepfake_model/config.json [Content-Type=application/json]...\n",
            "Copying file://deepfake_model/model.safetensors [Content-Type=application/octet-stream]...\n",
            "==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "-\n",
            "Operation completed over 3 objects/327.3 MiB.                                    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud services enable aiplatform.googleapis.com\n"
      ],
      "metadata": {
        "id": "1zLM7dK0Zypw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-aiplatform --upgrade\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMSsYnsoZ1fP",
        "outputId": "1784c5e3-8583-40ba-8642-ab58a8705e33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.12/dist-packages (1.113.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.25.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (5.29.5)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (25.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (2.19.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (3.36.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.14.2)\n",
            "Requirement already satisfied: shapely<3.0.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (2.1.1)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.33.0)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (2.11.7)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (4.15.0)\n",
            "Requirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (0.17.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.32.4)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (4.9.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.7.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform) (0.14.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage<3.0.0,>=1.32.0->google-cloud-aiplatform) (1.7.1)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (4.10.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (0.28.1)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (8.5.0)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (15.0.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.12/dist-packages (from shapely<3.0.0->google-cloud-aiplatform) (2.0.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "# Replace with your project and region\n",
        "PROJECT_ID = \"astral-net-472017-i3\"   # your GCP project ID\n",
        "REGION = \"asia-south1\"               # or asia-south1 for India\n",
        "BUCKET = \"hackathon1512\"          # the GCS bucket you uploaded deepfake_model\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET)\n"
      ],
      "metadata": {
        "id": "Ifumm1yoaSIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"deepfake_model\")\n",
        "processor.save_pretrained(\"deepfake_model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp0J8k3vagur",
        "outputId": "81d0e3e5-a2ec-48cb-e93f-6a166fb97a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['deepfake_model/preprocessor_config.json']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil cp -r deepfake_model gs://hackathon1512/deepfake_model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6bFjQXdanLp",
        "outputId": "c9205868-94d3-4ce4-c13a-51f31c7c1cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying file://deepfake_model/preprocessor_config.json [Content-Type=application/json]...\n",
            "Copying file://deepfake_model/config.json [Content-Type=application/json]...\n",
            "Copying file://deepfake_model/model.safetensors [Content-Type=application/octet-stream]...\n",
            "==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "-\n",
            "Operation completed over 3 objects/327.3 MiB.                                    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-model-archiver torchserve\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7Ry7siIcflo",
        "outputId": "d7329b66-d99f-4723-c36a-88ef7cab9943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch-model-archiver in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
            "Requirement already satisfied: torchserve in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
            "Requirement already satisfied: enum-compat in /usr/local/lib/python3.12/dist-packages (from torch-model-archiver) (0.0.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from torchserve) (11.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from torchserve) (5.9.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from torchserve) (25.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (from torchserve) (0.45.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deepfake_handler.py\n",
        "import torch\n",
        "from ts.torch_handler.vision_handler import VisionHandler\n",
        "\n",
        "class DeepFakeHandler(VisionHandler):\n",
        "    def __init__(self):\n",
        "        super(DeepFakeHandler, self).__init__()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYuN0SEvcjaB",
        "outputId": "4bcf807c-9583-4ad9-e3a7-709c979a0918"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing deepfake_handler.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 1: Authentication and Setup\n",
        "# ============================================\n",
        "from google.colab import auth\n",
        "import os\n",
        "auth.authenticate_user()\n",
        "\n",
        "# ============================================\n",
        "# CELL 2: Install Dependencies\n",
        "# ============================================\n",
        "!pip install --upgrade google-cloud-storage google-cloud-aiplatform google-cloud-functions\n",
        "!pip install transformers torch torchvision pillow opencv-python-headless\n",
        "!pip install flask flask-cors requests numpy pandas\n",
        "!pip install torch-model-archiver torchserve\n",
        "\n",
        "# ============================================\n",
        "# CELL 3: Project Configuration\n",
        "# ============================================\n",
        "import os\n",
        "from google.cloud import storage, aiplatform\n",
        "\n",
        "# Project configuration\n",
        "PROJECT_ID = \"astral-net-472017-i3\"\n",
        "REGION = \"asia-south1\"\n",
        "BUCKET_NAME = \"hackathon1512\"\n",
        "MODEL_NAME = \"deepfake-detector\"\n",
        "ENDPOINT_NAME = \"truthguard-endpoint\"\n",
        "\n",
        "# Set environment variables\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
        "\n",
        "# Enable GCP APIs\n",
        "!gcloud config set project {PROJECT_ID}\n",
        "!gcloud services enable compute.googleapis.com storage.googleapis.com aiplatform.googleapis.com cloudfunctions.googleapis.com\n",
        "\n",
        "# ============================================\n",
        "# CELL 4: Load and Test Deepfake Model\n",
        "# ============================================\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification, pipeline\n",
        "\n",
        "print(\"Loading deepfake detection model...\")\n",
        "processor = AutoImageProcessor.from_pretrained(\"prithivMLmods/Deep-Fake-Detector-v2-Model\")\n",
        "model = AutoModelForImageClassification.from_pretrained(\"prithivMLmods/Deep-Fake-Detector-v2-Model\")\n",
        "\n",
        "# Create pipeline\n",
        "pipe = pipeline(\"image-classification\", model=model, image_processor=processor)\n",
        "\n",
        "# Test the model\n",
        "print(\"Testing model...\")\n",
        "test_result = pipe(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/parrots.png\")\n",
        "print(f\"Test result: {test_result}\")\n",
        "\n",
        "# ============================================\n",
        "# CELL 5: Save Model Locally and Upload to GCS\n",
        "# ============================================\n",
        "import shutil\n",
        "import json\n",
        "from google.cloud import storage\n",
        "\n",
        "# Save locally\n",
        "model_dir = \"truthguard_deepfake_model\"\n",
        "model.save_pretrained(model_dir)\n",
        "processor.save_pretrained(model_dir)\n",
        "\n",
        "# Add metadata\n",
        "metadata = {\n",
        "    \"model_name\": \"TruthGuard Deepfake Detector\",\n",
        "    \"model_version\": \"1.0\",\n",
        "    \"framework\": \"transformers\",\n",
        "    \"input_type\": \"image\",\n",
        "    \"output_type\": \"classification\",\n",
        "    \"labels\": [\"Deepfake\", \"Real\"],\n",
        "    \"created_at\": \"2025-01-15\",\n",
        "    \"description\": \"Deep learning model for detecting deepfake images and videos\"\n",
        "}\n",
        "with open(f\"{model_dir}/metadata.json\", \"w\") as f:\n",
        "    json.dump(metadata, f, indent=2)\n",
        "\n",
        "# Upload model to GCS\n",
        "client = storage.Client(project=PROJECT_ID)\n",
        "try:\n",
        "    bucket = client.get_bucket(BUCKET_NAME)\n",
        "except:\n",
        "    bucket = client.create_bucket(BUCKET_NAME, location=REGION)\n",
        "\n",
        "for root, dirs, files in os.walk(model_dir):\n",
        "    for file in files:\n",
        "        local_path = os.path.join(root, file)\n",
        "        blob_path = f\"models/{model_dir}/{file}\"\n",
        "        blob = bucket.blob(blob_path)\n",
        "        blob.upload_from_filename(local_path)\n",
        "        print(f\"Uploaded {local_path} to gs://{BUCKET_NAME}/{blob_path}\")\n",
        "\n",
        "# ============================================\n",
        "# CELL 6: Create Prediction Handler\n",
        "# ============================================\n",
        "%%writefile prediction_handler.py\n",
        "import os\n",
        "import json\n",
        "import base64\n",
        "import io\n",
        "import logging\n",
        "from typing import Dict, Any\n",
        "from PIL import Image\n",
        "import torch\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification, pipeline\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class TruthGuardPredictor:\n",
        "    def __init__(self, model_dir: str = \"truthguard_deepfake_model\"):\n",
        "        self.model_dir = model_dir\n",
        "        self.model = None\n",
        "        self.processor = None\n",
        "        self.pipeline = None\n",
        "        self.load_model()\n",
        "\n",
        "    def load_model(self):\n",
        "        try:\n",
        "            logger.info(f\"Loading model from {self.model_dir}\")\n",
        "            self.processor = AutoImageProcessor.from_pretrained(self.model_dir)\n",
        "            self.model = AutoModelForImageClassification.from_pretrained(self.model_dir)\n",
        "            self.pipeline = pipeline(\"image-classification\", model=self.model, image_processor=self.processor)\n",
        "            logger.info(\"Model loaded successfully!\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error loading model: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def preprocess_image(self, image_data: str) -> Image.Image:\n",
        "        try:\n",
        "            if image_data.startswith('data:image'):\n",
        "                image_data = image_data.split(',')[1]\n",
        "            image_bytes = base64.b64decode(image_data)\n",
        "            image = Image.open(io.BytesIO(image_bytes))\n",
        "            if image.mode != 'RGB':\n",
        "                image = image.convert('RGB')\n",
        "            return image\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error preprocessing image: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def predict_image(self, image_data: str) -> Dict[str, Any]:\n",
        "        image = self.preprocess_image(image_data)\n",
        "        results = self.pipeline(image)\n",
        "        deepfake_score = 0.0\n",
        "        real_score = 0.0\n",
        "        for result in results:\n",
        "            if result['label'].lower() == 'deepfake':\n",
        "                deepfake_score = result['score']\n",
        "            else:\n",
        "                real_score = result['score']\n",
        "        is_deepfake = deepfake_score > real_score\n",
        "        confidence = max(deepfake_score, real_score)\n",
        "        return {\n",
        "            'is_deepfake': is_deepfake,\n",
        "            'deepfake_probability': float(deepfake_score),\n",
        "            'real_probability': float(real_score),\n",
        "            'confidence': float(confidence),\n",
        "            'risk_level': self._get_risk_level(deepfake_score),\n",
        "            'model_version': '1.0'\n",
        "        }\n",
        "\n",
        "    def _get_risk_level(self, deepfake_score: float) -> str:\n",
        "        if deepfake_score > 0.8:\n",
        "            return 'very_high'\n",
        "        elif deepfake_score > 0.6:\n",
        "            return 'high'\n",
        "        elif deepfake_score > 0.4:\n",
        "            return 'medium'\n",
        "        elif deepfake_score > 0.2:\n",
        "            return 'low'\n",
        "        else:\n",
        "            return 'very_low'\n",
        "\n",
        "# ============================================\n",
        "# CELL 7: Create Cloud Function Code\n",
        "# ============================================\n",
        "%%writefile cloud_function_main.py\n",
        "import os\n",
        "import json\n",
        "from flask import Flask, request, jsonify\n",
        "from google.cloud import storage\n",
        "import functions_framework\n",
        "from prediction_handler import TruthGuardPredictor\n",
        "\n",
        "app = Flask(__name__)\n",
        "predictor = None\n",
        "BUCKET_NAME = \"hackathon1512\"\n",
        "MODEL_DIR = \"truthguard_deepfake_model\"\n",
        "\n",
        "def initialize_predictor():\n",
        "    global predictor\n",
        "    if predictor is None:\n",
        "        if not os.path.exists(MODEL_DIR):\n",
        "            download_model_from_gcs()\n",
        "        predictor = TruthGuardPredictor(MODEL_DIR)\n",
        "\n",
        "def download_model_from_gcs():\n",
        "    client = storage.Client()\n",
        "    bucket = client.bucket(BUCKET_NAME)\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    blobs = bucket.list_blobs(prefix=f\"models/{MODEL_DIR}/\")\n",
        "    for blob in blobs:\n",
        "        if not blob.name.endswith('/'):\n",
        "            local_filename = blob.name.split('/')[-1]\n",
        "            local_path = os.path.join(MODEL_DIR, local_filename)\n",
        "            blob.download_to_filename(local_path)\n",
        "\n",
        "@functions_framework.http\n",
        "def predict_deepfake(request):\n",
        "    headers = {\n",
        "        'Access-Control-Allow-Origin': '*',\n",
        "        'Access-Control-Allow-Methods': 'POST, OPTIONS',\n",
        "        'Access-Control-Allow-Headers': 'Content-Type',\n",
        "    }\n",
        "    if request.method == 'OPTIONS':\n",
        "        return ('', 204, headers)\n",
        "    initialize_predictor()\n",
        "    request_json = request.get_json()\n",
        "    if 'image' in request_json:\n",
        "        result = predictor.predict_image(request_json['image'])\n",
        "        analysis_type = 'image'\n",
        "    else:\n",
        "        return jsonify({'error': 'No image data provided'}), 400\n",
        "    response_data = {\n",
        "        'success': True,\n",
        "        'analysis_type': analysis_type,\n",
        "        'results': result,\n",
        "        'model_info': {'name': 'TruthGuard Deepfake Detector', 'version': '1.0', 'framework': 'transformers'}\n",
        "    }\n",
        "    return (json.dumps(response_data), 200, headers)\n",
        "\n",
        "@app.route('/predict', methods=['POST', 'OPTIONS'])\n",
        "def local_predict():\n",
        "    return predict_deepfake(request)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True, port=8080)\n",
        "\n",
        "# ============================================\n",
        "# CELL 8: Create requirements.txt\n",
        "# ============================================\n",
        "%%writefile requirements.txt\n",
        "google-cloud-storage==2.19.0\n",
        "transformers==4.36.0\n",
        "torch==2.1.0\n",
        "torchvision==0.16.0\n",
        "Pillow==10.1.0\n",
        "opencv-python-headless==4.8.1.78\n",
        "numpy==1.24.3\n",
        "flask==3.0.0\n",
        "\n",
        "# ============================================\n",
        "# CELL 9: Frontend Configuration\n",
        "# ============================================\n",
        "%%writefile config.json\n",
        "{\n",
        "  \"gcp\": {\n",
        "    \"project_id\": \"astral-net-472017-i3\",\n",
        "    \"region\": \"asia-south1\",\n",
        "    \"bucket_name\": \"hackathon1512\",\n",
        "    \"function_url\": \"YOUR_FUNCTION_URL_HERE\",\n",
        "    \"model_name\": \"truthguard-deepfake-detector\"\n",
        "  },\n",
        "  \"api\": {\n",
        "    \"endpoints\": {\n",
        "      \"deepfake_detection\": \"/predict\"\n",
        "    }\n",
        "  },\n",
        "  \"limits\": {\n",
        "    \"max_file_size\": 16777216,\n",
        "    \"supported_formats\": {\n",
        "      \"images\": [\"jpg\", \"jpeg\", \"png\", \"gif\", \"bmp\", \"webp\"]\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "print(\"✅ Setup complete! Update FUNCTION_URL in config.json and deploy your Cloud Function.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "Ej-jdkgGdtfz",
        "outputId": "bb614a7c-7018-42c6-a279-fdc7a3c32753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-1822452552.py, line 245)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1822452552.py\"\u001b[0;36m, line \u001b[0;32m245\u001b[0m\n\u001b[0;31m    google-cloud-storage==2.19.0\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}